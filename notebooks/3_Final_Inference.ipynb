{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3_Final_Inference.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random  # <--- IMPORT ADDED\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "MODEL_PATH = '../saved_models/unet_oil_spill.h5' \n",
    "AIS_DATA_PATH = '../data/ais_data/vessel_data_clean.csv' \n",
    "\n",
    "# AUTOMATICALLY FIND A RANDOM TEST IMAGE\n",
    "TEST_DIR = '../data/test/images' \n",
    "TEST_IMG_PATH = None\n",
    "\n",
    "if os.path.exists(TEST_DIR):\n",
    "    # Get all files\n",
    "    files = os.listdir(TEST_DIR)\n",
    "    \n",
    "    # Filter to ensure we only pick images (jpg, png, etc.)\n",
    "    valid_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    images = [f for f in files if os.path.splitext(f)[1].lower() in valid_extensions]\n",
    "\n",
    "    if len(images) > 0:\n",
    "        # --- FIX IS HERE: Use random.choice() instead of files[0] ---\n",
    "        selected_file = random.choice(images)\n",
    "        TEST_IMG_PATH = os.path.join(TEST_DIR, selected_file)\n",
    "        print(f\"ðŸŽ² Randomly selected test image: {selected_file}\")\n",
    "    else:\n",
    "        print(\"WARNING: No valid images found in '../data/test/images'. Please add one!\")\n",
    "        TEST_IMG_PATH = 'dummy_path.jpg'\n",
    "else:\n",
    "    print(f\"Error: Directory {TEST_DIR} does not exist.\")\n",
    "    TEST_IMG_PATH = 'dummy_path.jpg' \n",
    "\n",
    "# --- 2. LOAD MODEL ---\n",
    "print(\"Loading Model...\")\n",
    "try:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Did you run '1_UNet_Training.ipynb' to generate the .h5 file?\")\n",
    "\n",
    "# --- 3. PREDICT FUNCTION (VISION) ---\n",
    "def predict_spill(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image not found at {image_path}\")\n",
    "        return np.zeros((256,256,3)), np.zeros((256,256,1))\n",
    "\n",
    "    # Preprocess\n",
    "    original_img = cv2.imread(image_path)\n",
    "    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = cv2.resize(original_img, (256, 256))\n",
    "    # Normalize (Crucial step)\n",
    "    img_input = np.expand_dims(img, axis=0) / 255.0 \n",
    "    \n",
    "    # Predict\n",
    "    raw_pred = model.predict(img_input)[0]\n",
    "    \n",
    "    # Debugging Statistics\n",
    "    print(f\"DEBUG: Model Output Stats -> Max: {np.max(raw_pred):.4f}, Mean: {np.mean(raw_pred):.4f}\")\n",
    "\n",
    "    # Thresholding: Reduced to 0.05 to capture low-confidence spills\n",
    "    mask_pred = (raw_pred > 0.05).astype(np.uint8) \n",
    "    \n",
    "    return img, mask_pred\n",
    "\n",
    "# --- 4. ANOMALY DETECTION (DATA LOGIC) ---\n",
    "def detect_anomaly(ais_csv, spill_lat, spill_lon, search_radius=0.5):\n",
    "    if not os.path.exists(ais_csv):\n",
    "        return [\"Error: AIS CSV file not found. Run '0_Prepare_AIS.py' first.\"]\n",
    "\n",
    "    df = pd.read_csv(ais_csv)\n",
    "    \n",
    "    nearby_ships = df[\n",
    "        (df['LAT'] > spill_lat - search_radius) & \n",
    "        (df['LAT'] < spill_lat + search_radius) & \n",
    "        (df['LON'] > spill_lon - search_radius) & \n",
    "        (df['LON'] < spill_lon + search_radius)\n",
    "    ]\n",
    "    \n",
    "    suspects = []\n",
    "    \n",
    "    if nearby_ships.empty:\n",
    "        suspects.append(\"No ships found in this area during this time.\")\n",
    "    else:\n",
    "        for index, ship in nearby_ships.iterrows():\n",
    "            speed = ship['SOG']\n",
    "            mmsi = ship['MMSI']\n",
    "            name = str(ship['VesselName'])\n",
    "            \n",
    "            if speed < 1.0: \n",
    "                suspects.append(f\"SUSPECT: {name} (ID: {mmsi}) - Speed: {speed} knots (STOPPED)\")\n",
    "            else:\n",
    "                suspects.append(f\"Clear: {name} (ID: {mmsi}) - Speed: {speed} knots (Moving)\")\n",
    "            \n",
    "    return suspects\n",
    "\n",
    "# --- 5. DAMAGE ASSESSMENT (NEW FEATURE) ---\n",
    "def assess_damage(mask):\n",
    "    # 1. Count the number of white pixels (Oil)\n",
    "    oil_pixel_count = np.count_nonzero(mask)\n",
    "    \n",
    "    # 2. Calculate Area based on Satellite Resolution\n",
    "    # Assumption: Sentinel-1 imagery is approx 10m x 10m per pixel (100 sq meters)\n",
    "    pixel_area_sq_m = 100 \n",
    "    \n",
    "    total_area_m2 = oil_pixel_count * pixel_area_sq_m\n",
    "    \n",
    "    # 3. Convert to Square Kilometers\n",
    "    total_area_km2 = total_area_m2 / 1_000_000\n",
    "    \n",
    "    print(\"\\n--- DAMAGE ASSESSMENT REPORT ---\")\n",
    "    print(f\"Detected Oil Pixels: {oil_pixel_count}\")\n",
    "    print(f\"Estimated Spill Area:  {total_area_km2:.4f} sq. km\")\n",
    "    \n",
    "    # 4. Define Severity Levels\n",
    "    if total_area_km2 > 1.0:\n",
    "        print(\"SEVERITY: CRITICAL - Large scale cleanup required immediately.\")\n",
    "    elif total_area_km2 > 0.1:\n",
    "        print(\"SEVERITY: HIGH - Containment booms advised.\")\n",
    "    elif total_area_km2 > 0.0:\n",
    "        print(\"SEVERITY: MODERATE - Minor leakage detected. Monitor closely.\")\n",
    "    else:\n",
    "        print(\"SEVERITY: NONE - No oil detected.\")\n",
    "\n",
    "# --- 6. RUN PIPELINE ---\n",
    "print(\"\\n--- STARTING ANALYSIS ---\")\n",
    "\n",
    "# A. Run Visual Detection\n",
    "final_img, final_mask = predict_spill(TEST_IMG_PATH)\n",
    "\n",
    "# B. Run Data Detection (Simulated Coordinates)\n",
    "simulated_lat = 28.5\n",
    "simulated_lon = -90.5\n",
    "anomalies = detect_anomaly(AIS_DATA_PATH, simulated_lat, simulated_lon)\n",
    "\n",
    "# C. Visualization (With Overlay)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 1. Original\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Satellite Input\")\n",
    "plt.imshow(final_img)\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. Mask (Multiplied by 255 to show White)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"AI Detected Spill (Mask)\")\n",
    "plt.imshow(final_mask * 255, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. Forensic Overlay (Red Spill on Original)\n",
    "mask_red = np.zeros_like(final_img)\n",
    "mask_red[:,:,0] = final_mask[:,:,0] * 255 # Set Red channel\n",
    "overlay = cv2.addWeighted(final_img, 0.7, mask_red, 0.3, 0)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Forensic Overlay\")\n",
    "plt.imshow(overlay)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# D. Run Damage Assessment\n",
    "assess_damage(final_mask)\n",
    "\n",
    "# E. Print AIS Forensic Report\n",
    "print(\"\\n--- AIS VESSEL FORENSIC REPORT ---\")\n",
    "print(f\"Searching for ships near Lat: {simulated_lat}, Lon: {simulated_lon}...\")\n",
    "# Print first 20 suspects\n",
    "for note in anomalies[:20]:\n",
    "    print(note)\n",
    "if len(anomalies) > 20:\n",
    "    print(f\"... and {len(anomalies)-20} more entries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
